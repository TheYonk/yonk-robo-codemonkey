# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/codegraph

# Embeddings Configuration
EMBEDDINGS_PROVIDER=ollama
EMBEDDINGS_MODEL=snowflake-arctic-embed2:latest
EMBEDDINGS_BASE_URL=http://localhost:11434
EMBEDDINGS_DIMENSION=1024
MAX_CHUNK_LENGTH=8192
EMBEDDING_BATCH_SIZE=100

# Alternative models:
# - nomic-embed-text (768 dimensions, 2048 token limit)
# - snowflake-arctic-embed2:latest (1024 dimensions, 8192 token limit) - RECOMMENDED
# - text-embedding-3-small (1536 dimensions) - requires OpenAI API

# vLLM Configuration (alternative to Ollama)
VLLM_BASE_URL=http://localhost:8000
VLLM_API_KEY=local-key

# Repository Scanning
REPO_ROOT=/path/to/your/repo
IGNORE_FILE=.gitignore
WATCH_MODE=false

# Search Parameters
VECTOR_TOP_K=30
FTS_TOP_K=30
FINAL_TOP_K=12
CONTEXT_BUDGET_TOKENS=12000
GRAPH_DEPTH=2

# Schema Isolation (one schema per repo)
SCHEMA_PREFIX=codegraph_
USE_SCHEMAS=true
