# RoboMonkey Docker Deployment Configuration
# Copy this file to .env and customize as needed

# PostgreSQL Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=robomonkey
POSTGRES_PORT=5433

# Embeddings Configuration
# Note: Embeddings in the backup were generated with a specific model.
# For vector search to work correctly, use the same model or regenerate embeddings.
EMBEDDINGS_PROVIDER=ollama
EMBEDDINGS_MODEL=snowflake-arctic-embed2:latest
EMBEDDINGS_BASE_URL=http://ollama:11434
EMBEDDINGS_DIMENSION=1024

# Default repository for MCP queries
DEFAULT_REPO=sko_test

# Optional: Remap source code paths during restore
# Set this if you want to update the root_path in the restored repo
# NEW_ROOT_PATH=/app/source-code

# Ollama Configuration (if using --profile full)
OLLAMA_PORT=11434

# =============================================================================
# LLM Configuration (for summaries and analysis)
# =============================================================================
# Provider options: ollama, openai, vllm
# LLM_PROVIDER=ollama

# For Ollama (local):
# LLM_DEEP_MODEL=qwen2.5-coder:14b
# LLM_SMALL_MODEL=qwen2.5-coder:7b
# LLM_BASE_URL=http://ollama:11434

# For OpenAI (cloud):
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# Deep models: gpt-5.2-codex, gpt-5.2, gpt-5.2-pro, gpt-5, gpt-4.1
# LLM_DEEP_MODEL=gpt-5.2-codex
# Small models: gpt-5-mini, gpt-5-nano
# LLM_SMALL_MODEL=gpt-5-mini
# LLM_BASE_URL=https://api.openai.com
